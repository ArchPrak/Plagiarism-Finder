{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install metaphor-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yd7bEfvizb1",
        "outputId": "e28045ce-538f-4bc6-e70e-9e0bb9f1c6e1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: metaphor-python in /usr/local/lib/python3.10/dist-packages (0.1.16)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from metaphor-python) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->metaphor-python) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->metaphor-python) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->metaphor-python) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->metaphor-python) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Load the spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to extract text from HTML\n",
        "def extract_text_from_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    text = \"\"\n",
        "    for paragraph in soup.find_all(\"p\"):\n",
        "        text += paragraph.get_text() + \" \"\n",
        "    return text\n",
        "\n",
        "# Function to generate a shorter search query (limit to 20 words)\n",
        "def generate_short_search_query(text, max_words=20):\n",
        "    doc = nlp(text)\n",
        "    keywords = []\n",
        "\n",
        "    # Extract nouns and adjectives as keywords\n",
        "    for token in doc:\n",
        "        if token.pos_ in (\"NOUN\", \"ADJ\"):\n",
        "            keywords.append(token.text)\n",
        "\n",
        "    # Limit the keywords to a maximum of max_words\n",
        "    keywords = keywords[:max_words]\n",
        "\n",
        "    # Join keywords into a search query\n",
        "    query = \" \".join(keywords)\n",
        "    return query\n",
        "\n",
        "def generate_search_query_for_html(html_content):\n",
        "    text = extract_text_from_html(html_content)\n",
        "    search_query = generate_short_search_query(text, max_words=20)\n",
        "    print(\"Generated Short Search Query (up to 20 words):\", search_query)\n",
        "    return search_query\n"
      ],
      "metadata": {
        "id": "EBWgsGiVueZV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similar_urls(source_url):\n",
        "  result = ''\n",
        "  try:\n",
        "    response = metaphor_client.find_similar(source_url, num_results = 10)\n",
        "    matching_results = []\n",
        "    for res in response.results:\n",
        "      # print(res.title, res.url)\n",
        "      result += res.title + \" \" + res.url + '\\n'\n",
        "    # print(result)\n",
        "    return (response, result)\n",
        "  except:\n",
        "    raise Exception(\"There seems to be something wrong with the URL you entered, please check\")\n",
        "\n",
        "def get_html_content(response):\n",
        "  #----------------------------- Finding content of the project -----------------------------\n",
        "  top_match_url = response.results[0].url # using top match for extracting content of the project\n",
        "  top_match_id = response.results[0].id\n",
        "  contents = metaphor_client.get_contents([top_match_id])\n",
        "  return contents\n",
        "\n",
        "\n",
        "def find_similar_content(content):\n",
        "  #-------------------- Generating a search query to retrieve similar content -----------------\n",
        "  search_query = generate_search_query_for_html(content.contents[0].extract)\n",
        "  response = metaphor_client.search(\n",
        "  search_query,\n",
        "  num_results=10,\n",
        "  use_autoprompt=True,\n",
        "  )\n",
        "  return (response)\n",
        "\n"
      ],
      "metadata": {
        "id": "Fgr_-hRNjOkZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "lgYIYQ4Sisbj"
      },
      "outputs": [],
      "source": [
        "#----------------------------- Initialising Metaphor Client -----------------------------\n",
        "from metaphor_python import Metaphor\n",
        "ACCESS_KEY = \"b466d1c1-82bb-474e-a6c9-1375ae07ba6c\" # ideally this would be fetched from a file\n",
        "metaphor_client = Metaphor(ACCESS_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    report_string = \\\n",
        "    '''\\n_________________________________________________________________\n",
        "      \\nPLAGIRAISM REPORT: SIMILAR INFORMATION FOUND ONLINE\n",
        "      \\n__________________________________________________________________\n",
        "    '''\n",
        "    source_url = input(\"Enter URL of Project\")\n",
        "    output_file = \"plagiarism_report.txt\"\n",
        "    print(\"Thanks! Checking for plagiarism - similar content across the web ...\")\n",
        "    response, result = get_similar_urls(source_url)\n",
        "\n",
        "    report_string += result\n",
        "\n",
        "    contents = get_html_content(response)\n",
        "    # print(response)\n",
        "    response = find_similar_content(contents)\n",
        "\n",
        "    report_string += \"\\nOther similar sources: \\n\"\n",
        "    for res in response.results:\n",
        "      report_string += str(res) + \"\\n\"\n",
        "\n",
        "    print(report_string)\n",
        "    print(\"Done! Find your results in : \", output_file)\n",
        "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "       file.write(report_string)\n"
      ],
      "metadata": {
        "id": "mAvL0gXJ7zOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(response.results[0])\n",
        "print(str(response.results[0]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpD_kivt-6yB",
        "outputId": "ec1f0f38-4dac-4df4-f85d-6d3fbfd42912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Title: GitHub - CommissarMa/Crowd_counting_from_scratch: This is an overview and tutorial about crowd counting. In this repository, you can learn how to estimate number of pedestrians in crowd scenes through computer vision and deep learning.\n",
            "URL: https://github.com/CommissarMa/Crowd_counting_from_scratch\n",
            "ID: j8WEU8v-BDkOMVEH8tdLsQ\n",
            "Score: 0.17051389813423157\n",
            "Published Date: 2023-01-01\n",
            "Author: CommissarMa\n",
            "Extract: None\n",
            "Title: GitHub - CommissarMa/Crowd_counting_from_scratch: This is an overview and tutorial about crowd counting. In this repository, you can learn how to estimate number of pedestrians in crowd scenes through computer vision and deep learning.\n",
            "URL: https://github.com/CommissarMa/Crowd_counting_from_scratch\n",
            "ID: j8WEU8v-BDkOMVEH8tdLsQ\n",
            "Score: 0.17051389813423157\n",
            "Published Date: 2023-01-01\n",
            "Author: CommissarMa\n",
            "Extract: None\n",
            "\n",
            "Title: Crowd Counting | Building Crowd Counting Model Using Python\n",
            "URL: https://www.analyticsvidhya.com/blog/2019/02/building-crowd-counting-model-python/\n",
            "ID: lRbW2piL3SWQIdff__U0xQ\n",
            "Score: 0.1700657457113266\n",
            "Published Date: 2019-02-18\n",
            "Author: Pulkit Sharma\n",
            "Extract: None\n",
            "\n",
            "Title: GitHub - ChuyiZhong/Multiple-Crowd-abnormal-behavior-detection\n",
            "URL: https://github.com/ChuyiZhong/Multiple-Crowd-abnormal-behavior-detection\n",
            "ID: q48Y_Tf7B9Q2KdWk4qflnQ\n",
            "Score: 0.16903693974018097\n",
            "Published Date: 2023-01-01\n",
            "Author: ChuyiZhong\n",
            "Extract: None\n",
            "\n",
            "Title: GitHub - RQuispeC/multi-stream-crowd-counting: Official implementation of \"Where are the People? A Multi-Stream Convolutional Neural Network for Crowd Counting via Density Map from Complex Images\" presented in IWSSIP 2019\n",
            "URL: https://github.com/RQuispeC/multi-stream-crowd-counting\n",
            "ID: 9T-onLD3e4MH2u68C5e8Uw\n",
            "Score: 0.1636672019958496\n",
            "Published Date: 2023-01-01\n",
            "Author: RQuispeC\n",
            "Extract: None\n",
            "\n",
            "Title: GitHub - imkanghan/crowd-counting: Image Crowd Counting Using Convolutional Neural Network and Markov Random Field\n",
            "URL: https://github.com/imkanghan/crowd-counting\n",
            "ID: 1Ol2GDRhddsq1KaTA8YfTA\n",
            "Score: 0.16269364953041077\n",
            "Published Date: 2023-01-01\n",
            "Author: Imkanghan\n",
            "Extract: None\n",
            "\n",
            "Title: GitHub - nspunn1993/Crowd-Behavior-Analysis-using-Faster-RCNN: Crowd Analysis for Congestion Control Early Warning System on Foot Over Bridge\n",
            "URL: https://github.com/nspunn1993/Crowd-Behavior-Analysis-using-Faster-RCNN\n",
            "ID: dDob7OFT1ZAeQoy9lL9DWw\n",
            "Score: 0.1549527943134308\n",
            "Published Date: 2023-01-01\n",
            "Author: Nspunn\n",
            "Extract: None\n",
            "\n",
            "Title: Bingzhe's Blog\n",
            "URL: https://bingzhewu.github.io/tags/Deep-Learning/\n",
            "ID: E9KGd6guHomYfdjFd9Z6Pg\n",
            "Score: 0.1492181420326233\n",
            "Published Date: 2017-06-20\n",
            "Author: None\n",
            "Extract: None\n",
            "\n",
            "Title: handson-ml2/14_deep_computer_vision_with_cnns.ipynb at master Â· ageron/handson-ml2\n",
            "URL: https://github.com/ageron/handson-ml2/blob/master/14_deep_computer_vision_with_cnns.ipynb\n",
            "ID: _BZbivesZ0F83b-sx155iQ\n",
            "Score: 0.1482921540737152\n",
            "Published Date: 2023-01-01\n",
            "Author: Ageron\n",
            "Extract: None\n",
            "\n",
            "Title: None\n",
            "URL: https://course18.fast.ai/lessons/lessons2.html\n",
            "ID: sOGsYvkWlOZ0OKrzDXpN8g\n",
            "Score: 0.14796382188796997\n",
            "Published Date: 2016-01-01\n",
            "Author: None\n",
            "Extract: None\n",
            "\n",
            "Title: GitHub - vishal-siddegowda/CrowdAnomalyDetection_DeepLearning: In the recent times, machine learning and deep learning have demonstrated an key advancement in the field of anomaly detection especially in the crowd. This progress has impacted immensely in detecting suspicious/abnormal activity such as robbery, vandalism, stempedes, road rage, and so on. For the purpose of this study, transfer learning is employed because of it proven efficiency to train on a small dataset yet producing a promising output. Transfer learning is utilized to train the dataset using Visual Geometry Group network 19 (VGGNet-19) and Visual Geometry Group network 16 (VGGNet-16) pre-trained network to extract the human motion features from a RGB video data. The designed model is employed on two dataset, UMN(University of Minnesota) and WEB crowd dataset to achieve the objective. Analysing the experimental results, VGGNet-19 has been demonstrated a good quality performance of approximately 98% on UMN data while VGGNet-16 has produced a approximately 58% on WEB dataset.\n",
            "URL: https://github.com/vishal-siddegowda/CrowdAnomalyDetection_DeepLearning\n",
            "ID: LS94JLdxKAIgPDZ8jNg_HQ\n",
            "Score: 0.14739760756492615\n",
            "Published Date: 2023-01-01\n",
            "Author: Vishal-Siddegowda\n",
            "Extract: None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(contents_result.contents[0].extract))"
      ],
      "metadata": {
        "id": "9_50e0EtsjUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_search_query_for_html(contents_result.contents[0].extract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "eoHlNwIZv-ZI",
        "outputId": "936c3c0f-f69e-45e2-cb9f-8ac6938f8b51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Short Search Query (up to 20 words): project deep network able occurrence stampede crowd images different sources dataset grayscale images configuration auto- encoder multi - column auto\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'project deep network able occurrence stampede crowd images different sources dataset grayscale images configuration auto- encoder multi - column auto'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_report"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bPiPotKE0Gnm",
        "outputId": "87eeb086-5365-461b-b0be-ffe20b038da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bqyiZuiG4PC7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}